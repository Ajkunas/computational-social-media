{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9543efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sentiment_first.csv', usecols=['user_name', 'user_description', 'clean_tweets', 'tweets','label', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1906c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fab585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>tweets</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>norman meuschke</td>\n",
       "      <td>postdoc gipplab unigoettingen phd unikonstanz ...</td>\n",
       "      <td>#ChatGPT and similar #LLM pose a challenge to ...</td>\n",
       "      <td>chatgpt similar llm pose challenge academic in...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-05 17:08:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>devang</td>\n",
       "      <td>passionate nature software developer profession</td>\n",
       "      <td>Was just wondering is there any difference bet...</td>\n",
       "      <td>wondering difference jasper chatgpt gpt chatgp...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-05 17:08:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gabriel furstenheim</td>\n",
       "      <td>mathematician developer amazon previously geob...</td>\n",
       "      <td>Russel vs ChatGPT. It's also funny that it tak...</td>\n",
       "      <td>russel chatgpt it funny take long time answer ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-05 17:09:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iamtmoyo</td>\n",
       "      <td>blockchain enthusiast philanthropist slave jav...</td>\n",
       "      <td>Levelsüôèüôèüôè,so happy for the chatGPT team for co...</td>\n",
       "      <td>levelsso happy chatgpt team com revolutionary ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-05 17:10:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nenu</td>\n",
       "      <td>brain meant processing million tweet post vide...</td>\n",
       "      <td>ChatGPT is the biggest, smartest brain üß† in th...</td>\n",
       "      <td>chatgpt biggest smartest brain world right now...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-05 17:11:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52332</th>\n",
       "      <td>lakejoco</td>\n",
       "      <td>inspired meme forager rambler</td>\n",
       "      <td>Podcast returns in 2023! üêàüåô\\n.\\n#ai #chatgpt #...</td>\n",
       "      <td>podcast return chatgpt artificialintelligence ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-31 23:56:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52333</th>\n",
       "      <td>vinny carpenter</td>\n",
       "      <td>geek mission life strive seek find yield opini...</td>\n",
       "      <td>One of my new favorite thing to do with #ChatG...</td>\n",
       "      <td>new favorite thing chatgpt create playlist her...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-31 23:58:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52334</th>\n",
       "      <td>kawtar choubari</td>\n",
       "      <td>content creator software engineer tweet progra...</td>\n",
       "      <td>Sounds like AI can't predict 2023 trends üòÜ\\n#n...</td>\n",
       "      <td>sound like cant predict trend newyear chatgpt ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-12-31 23:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52335</th>\n",
       "      <td>yordan dimitrov</td>\n",
       "      <td>focusing seo techcharities more tweeting lates...</td>\n",
       "      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n",
       "      <td>asked chatgpt write nye joke seos delivered se...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-31 23:59:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52336</th>\n",
       "      <td>jean burellier</td>\n",
       "      <td>professor supinfo principal engineer talk engi...</td>\n",
       "      <td>2023 predictions by #chatGPT. Nothing really s...</td>\n",
       "      <td>prediction chatgpt specific trend past year to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-31 23:59:50+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52337 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_name                                   user_description  \\\n",
       "0          norman meuschke  postdoc gipplab unigoettingen phd unikonstanz ...   \n",
       "1                   devang    passionate nature software developer profession   \n",
       "2      gabriel furstenheim  mathematician developer amazon previously geob...   \n",
       "3                 iamtmoyo  blockchain enthusiast philanthropist slave jav...   \n",
       "4                     nenu  brain meant processing million tweet post vide...   \n",
       "...                    ...                                                ...   \n",
       "52332             lakejoco                      inspired meme forager rambler   \n",
       "52333      vinny carpenter  geek mission life strive seek find yield opini...   \n",
       "52334      kawtar choubari  content creator software engineer tweet progra...   \n",
       "52335      yordan dimitrov  focusing seo techcharities more tweeting lates...   \n",
       "52336       jean burellier  professor supinfo principal engineer talk engi...   \n",
       "\n",
       "                                                  tweets  \\\n",
       "0      #ChatGPT and similar #LLM pose a challenge to ...   \n",
       "1      Was just wondering is there any difference bet...   \n",
       "2      Russel vs ChatGPT. It's also funny that it tak...   \n",
       "3      Levelsüôèüôèüôè,so happy for the chatGPT team for co...   \n",
       "4      ChatGPT is the biggest, smartest brain üß† in th...   \n",
       "...                                                  ...   \n",
       "52332  Podcast returns in 2023! üêàüåô\\n.\\n#ai #chatgpt #...   \n",
       "52333  One of my new favorite thing to do with #ChatG...   \n",
       "52334  Sounds like AI can't predict 2023 trends üòÜ\\n#n...   \n",
       "52335  I asked #ChatGPT to write a #NYE Joke for SEOs...   \n",
       "52336  2023 predictions by #chatGPT. Nothing really s...   \n",
       "\n",
       "                                            clean_tweets     label  \\\n",
       "0      chatgpt similar llm pose challenge academic in...  positive   \n",
       "1      wondering difference jasper chatgpt gpt chatgp...   neutral   \n",
       "2      russel chatgpt it funny take long time answer ...   neutral   \n",
       "3      levelsso happy chatgpt team com revolutionary ...  positive   \n",
       "4      chatgpt biggest smartest brain world right now...  positive   \n",
       "...                                                  ...       ...   \n",
       "52332  podcast return chatgpt artificialintelligence ...  positive   \n",
       "52333  new favorite thing chatgpt create playlist her...  positive   \n",
       "52334  sound like cant predict trend newyear chatgpt ...  negative   \n",
       "52335  asked chatgpt write nye joke seos delivered se...   neutral   \n",
       "52336  prediction chatgpt specific trend past year to...   neutral   \n",
       "\n",
       "                            date  \n",
       "0      2022-12-05 17:08:20+00:00  \n",
       "1      2022-12-05 17:08:44+00:00  \n",
       "2      2022-12-05 17:09:04+00:00  \n",
       "3      2022-12-05 17:10:31+00:00  \n",
       "4      2022-12-05 17:11:10+00:00  \n",
       "...                          ...  \n",
       "52332  2022-12-31 23:56:28+00:00  \n",
       "52333  2022-12-31 23:58:31+00:00  \n",
       "52334  2022-12-31 23:58:37+00:00  \n",
       "52335  2022-12-31 23:59:30+00:00  \n",
       "52336  2022-12-31 23:59:50+00:00  \n",
       "\n",
       "[52337 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37663cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cedeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>tweets</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10943</th>\n",
       "      <td>shoshana weissmann sloth committee chair</td>\n",
       "      <td>digital director fellow rsi occupational licen...</td>\n",
       "      <td>Telling #ChatGPT to make things pokemon is my ...</td>\n",
       "      <td>telling chatgpt thing pokemon new reason livin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-07 15:08:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11280</th>\n",
       "      <td>chris black azure mvp happy azure stacking</td>\n",
       "      <td>azure stack family evangelist azure stack hub ...</td>\n",
       "      <td>This is legit amazing! #AzureStackHub #AzureSt...</td>\n",
       "      <td>legit amazing azurestackhub azurestack chatgpt</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-07 16:56:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22644</th>\n",
       "      <td>michal jirak</td>\n",
       "      <td>building tech company europe mitoncz founder p...</td>\n",
       "      <td>Seeing the buzz around #chatGPT, you realize h...</td>\n",
       "      <td>seeing buzz chatgpt realize ahead time hertlin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-10 12:13:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51216</th>\n",
       "      <td>philippe jeanbaptiste</td>\n",
       "      <td>consultant managing director author teach phd ...</td>\n",
       "      <td>#ChatGPT #GenerativeAI #History Why AI Won‚Äôt S...</td>\n",
       "      <td>chatgpt generativeai history won steal medieva...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-12-31 01:14:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>suraj</td>\n",
       "      <td>sport technology sneaker chelsea dab cover</td>\n",
       "      <td>ChatGPT reminds me of the time I explored http...</td>\n",
       "      <td>chatgpt reminds time explored literally asking...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-08 19:57:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33844</th>\n",
       "      <td>gemhunter</td>\n",
       "      <td>bought coti fet bitcoin matic ftm gemhunter fo...</td>\n",
       "      <td>I'm just amazed by the strength of $AGIX(#AGIX...</td>\n",
       "      <td>amazed strength agixagix bitcoin handling good...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-19 22:54:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>automaticjack</td>\n",
       "      <td>sysadmin infosec eng wont answer phone ever co...</td>\n",
       "      <td>the #chatGPT team handling human input and the...</td>\n",
       "      <td>chatgpt team handling human input limit clear ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-06 01:38:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>fabian williams</td>\n",
       "      <td>senior product manager microsoft microsoftgrap...</td>\n",
       "      <td>Came to learn more about #ChatGPT but stayed f...</td>\n",
       "      <td>came learn chatgpt stayed jailbreak safety gua...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-12-10 15:01:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39219</th>\n",
       "      <td>swisscognitive worldleading network</td>\n",
       "      <td>crossindustry global community business leader...</td>\n",
       "      <td>The first film written and directed by #Artifi...</td>\n",
       "      <td>film written directed artificialintelligence f...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-22 20:45:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46128</th>\n",
       "      <td>sarbjeet johal</td>\n",
       "      <td>year year cloud gtm coder economist storytelle...</td>\n",
       "      <td>@MDMGeek @sama @furrier @glassaxe_dj @profgall...</td>\n",
       "      <td>mdmgeek sama furrier glassaxedj profgalloway k...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-27 21:17:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9807</th>\n",
       "      <td>toby walsh</td>\n",
       "      <td>machine behaving badly now laureate fellow sci...</td>\n",
       "      <td>Catch me on ABC's PM programme talking about C...</td>\n",
       "      <td>catch abc programme talking chatgpt unswai cha...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-07 09:55:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51000</th>\n",
       "      <td>peter csathy creative medium</td>\n",
       "      <td>entertainment medium music web nft tech expert...</td>\n",
       "      <td>Okay all you #ChatGPT &amp;amp;is  #AI'ers out the...</td>\n",
       "      <td>okay chatgpt ampis aiers which everyone eve ne...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-30 21:35:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23143</th>\n",
       "      <td>marco russo</td>\n",
       "      <td>consultant speaker book writer mentor business...</td>\n",
       "      <td>Is it possible that the #ChatGPT understands t...</td>\n",
       "      <td>possible chatgpt understands repeating lie mak...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-12-10 15:25:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35465</th>\n",
       "      <td>richard kim</td>\n",
       "      <td>news paper book machine learning deep learning...</td>\n",
       "      <td>The 3 Best #AI Stocks to Buy as #ChatGPT Usher...</td>\n",
       "      <td>best stock buy chatgpt usher chatbot revolutio...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-20 20:59:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18547</th>\n",
       "      <td>torben andersen</td>\n",
       "      <td>rks tter tidl ceo cofounder robinhus pipper al...</td>\n",
       "      <td>Hot take on #ChatGPT: Current iteration is 100...</td>\n",
       "      <td>hot chatgpt current iteration guy cruise verba...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-12-09 10:30:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>jonah adkins</td>\n",
       "      <td>cartography lead meta stamen openstreetmap ope...</td>\n",
       "      <td>Hans Moleman, ethical cartographer #ChatGPT ht...</td>\n",
       "      <td>han moleman ethical cartographer chatgpt</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-07 01:24:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35935</th>\n",
       "      <td>santosh kamane</td>\n",
       "      <td>cybesecurity leader ciso speaker passionate bu...</td>\n",
       "      <td>2023 key threats and responses \\n\\n#cybersecur...</td>\n",
       "      <td>key threat response cybersecurity artificialin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-21 04:18:55+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45892</th>\n",
       "      <td>astrorich</td>\n",
       "      <td>space math geek</td>\n",
       "      <td>cc @JackRhysider @ADanielHill Interesting clai...</td>\n",
       "      <td>jackrhysider adanielhill interesting claim cha...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-27 18:40:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41188</th>\n",
       "      <td>andy black</td>\n",
       "      <td>associate professor murray state university da...</td>\n",
       "      <td>#ChatGPT and I co-authored one of the most pot...</td>\n",
       "      <td>chatgpt coauthored potent ampominous political...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-24 00:23:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>ryan cromwell</td>\n",
       "      <td>dad big vision small change learning</td>\n",
       "      <td>You've got my attention, #ChatGPT!\\n\\n@Salesfo...</td>\n",
       "      <td>youve got attention chatgpt salesforcedevs</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-12-06 21:53:19+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_name  \\\n",
       "10943    shoshana weissmann sloth committee chair   \n",
       "11280  chris black azure mvp happy azure stacking   \n",
       "22644                                michal jirak   \n",
       "51216                       philippe jeanbaptiste   \n",
       "16171                                       suraj   \n",
       "33844                                   gemhunter   \n",
       "2316                                automaticjack   \n",
       "23086                             fabian williams   \n",
       "39219         swisscognitive worldleading network   \n",
       "46128                              sarbjeet johal   \n",
       "9807                                   toby walsh   \n",
       "51000                peter csathy creative medium   \n",
       "23143                                 marco russo   \n",
       "35465                                 richard kim   \n",
       "18547                             torben andersen   \n",
       "8137                                 jonah adkins   \n",
       "35935                              santosh kamane   \n",
       "45892                                   astrorich   \n",
       "41188                                  andy black   \n",
       "7438                                ryan cromwell   \n",
       "\n",
       "                                        user_description  \\\n",
       "10943  digital director fellow rsi occupational licen...   \n",
       "11280  azure stack family evangelist azure stack hub ...   \n",
       "22644  building tech company europe mitoncz founder p...   \n",
       "51216  consultant managing director author teach phd ...   \n",
       "16171         sport technology sneaker chelsea dab cover   \n",
       "33844  bought coti fet bitcoin matic ftm gemhunter fo...   \n",
       "2316   sysadmin infosec eng wont answer phone ever co...   \n",
       "23086  senior product manager microsoft microsoftgrap...   \n",
       "39219  crossindustry global community business leader...   \n",
       "46128  year year cloud gtm coder economist storytelle...   \n",
       "9807   machine behaving badly now laureate fellow sci...   \n",
       "51000  entertainment medium music web nft tech expert...   \n",
       "23143  consultant speaker book writer mentor business...   \n",
       "35465  news paper book machine learning deep learning...   \n",
       "18547  rks tter tidl ceo cofounder robinhus pipper al...   \n",
       "8137   cartography lead meta stamen openstreetmap ope...   \n",
       "35935  cybesecurity leader ciso speaker passionate bu...   \n",
       "45892                                    space math geek   \n",
       "41188  associate professor murray state university da...   \n",
       "7438                dad big vision small change learning   \n",
       "\n",
       "                                                  tweets  \\\n",
       "10943  Telling #ChatGPT to make things pokemon is my ...   \n",
       "11280  This is legit amazing! #AzureStackHub #AzureSt...   \n",
       "22644  Seeing the buzz around #chatGPT, you realize h...   \n",
       "51216  #ChatGPT #GenerativeAI #History Why AI Won‚Äôt S...   \n",
       "16171  ChatGPT reminds me of the time I explored http...   \n",
       "33844  I'm just amazed by the strength of $AGIX(#AGIX...   \n",
       "2316   the #chatGPT team handling human input and the...   \n",
       "23086  Came to learn more about #ChatGPT but stayed f...   \n",
       "39219  The first film written and directed by #Artifi...   \n",
       "46128  @MDMGeek @sama @furrier @glassaxe_dj @profgall...   \n",
       "9807   Catch me on ABC's PM programme talking about C...   \n",
       "51000  Okay all you #ChatGPT &amp;is  #AI'ers out the...   \n",
       "23143  Is it possible that the #ChatGPT understands t...   \n",
       "35465  The 3 Best #AI Stocks to Buy as #ChatGPT Usher...   \n",
       "18547  Hot take on #ChatGPT: Current iteration is 100...   \n",
       "8137   Hans Moleman, ethical cartographer #ChatGPT ht...   \n",
       "35935  2023 key threats and responses \\n\\n#cybersecur...   \n",
       "45892  cc @JackRhysider @ADanielHill Interesting clai...   \n",
       "41188  #ChatGPT and I co-authored one of the most pot...   \n",
       "7438   You've got my attention, #ChatGPT!\\n\\n@Salesfo...   \n",
       "\n",
       "                                            clean_tweets     label  \\\n",
       "10943  telling chatgpt thing pokemon new reason livin...  positive   \n",
       "11280     legit amazing azurestackhub azurestack chatgpt  positive   \n",
       "22644  seeing buzz chatgpt realize ahead time hertlin...  positive   \n",
       "51216  chatgpt generativeai history won steal medieva...  negative   \n",
       "16171  chatgpt reminds time explored literally asking...  positive   \n",
       "33844  amazed strength agixagix bitcoin handling good...  positive   \n",
       "2316   chatgpt team handling human input limit clear ...  positive   \n",
       "23086  came learn chatgpt stayed jailbreak safety gua...  negative   \n",
       "39219  film written directed artificialintelligence f...   neutral   \n",
       "46128  mdmgeek sama furrier glassaxedj profgalloway k...  positive   \n",
       "9807   catch abc programme talking chatgpt unswai cha...   neutral   \n",
       "51000  okay chatgpt ampis aiers which everyone eve ne...  positive   \n",
       "23143  possible chatgpt understands repeating lie mak...  negative   \n",
       "35465  best stock buy chatgpt usher chatbot revolutio...   neutral   \n",
       "18547  hot chatgpt current iteration guy cruise verba...  negative   \n",
       "8137            han moleman ethical cartographer chatgpt   neutral   \n",
       "35935  key threat response cybersecurity artificialin...   neutral   \n",
       "45892  jackrhysider adanielhill interesting claim cha...   neutral   \n",
       "41188  chatgpt coauthored potent ampominous political...  positive   \n",
       "7438          youve got attention chatgpt salesforcedevs  positive   \n",
       "\n",
       "                            date  \n",
       "10943  2022-12-07 15:08:50+00:00  \n",
       "11280  2022-12-07 16:56:00+00:00  \n",
       "22644  2022-12-10 12:13:08+00:00  \n",
       "51216  2022-12-31 01:14:04+00:00  \n",
       "16171  2022-12-08 19:57:45+00:00  \n",
       "33844  2022-12-19 22:54:34+00:00  \n",
       "2316   2022-12-06 01:38:56+00:00  \n",
       "23086  2022-12-10 15:01:21+00:00  \n",
       "39219  2022-12-22 20:45:16+00:00  \n",
       "46128  2022-12-27 21:17:16+00:00  \n",
       "9807   2022-12-07 09:55:04+00:00  \n",
       "51000  2022-12-30 21:35:51+00:00  \n",
       "23143  2022-12-10 15:25:41+00:00  \n",
       "35465  2022-12-20 20:59:45+00:00  \n",
       "18547  2022-12-09 10:30:40+00:00  \n",
       "8137   2022-12-07 01:24:12+00:00  \n",
       "35935  2022-12-21 04:18:55+00:00  \n",
       "45892  2022-12-27 18:40:13+00:00  \n",
       "41188  2022-12-24 00:23:12+00:00  \n",
       "7438   2022-12-06 21:53:19+00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9912aba",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31ce706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# remove english stopwords with the help of the gensim library \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a398885",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "# cleaning and removing URLs\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "def remove_hyperlink(word):\n",
    "    return re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "# cleaning and removing mentions \n",
    "def remove_mentions(word):\n",
    "    return re.sub(r\"@\\S+\", \"\", word)\n",
    "\n",
    "# removing emojis \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# cleaning and removing repeating characters\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lematize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eee89322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    # cleaning and removing URLs\n",
    "    df = df.apply(lambda x: cleaning_URLs(x))\n",
    "    df = df.apply(lambda x: remove_hyperlink(x))\n",
    "    print(\"Cleaned and removed the URLs and hyperlinks.\")\n",
    "    \n",
    "    # cleaning and removing mentions \n",
    "    df = df.apply(lambda x: remove_mentions(x))\n",
    "    print(\"Cleaned and removed the mentions.\")\n",
    "    \n",
    "    # write new csv file containing the preprocessed dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057073ca",
   "metadata": {},
   "source": [
    "## Sentiment evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "364a58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(sample.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d098f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(sample.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77b3ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You've got my attention, #ChatGPT!\\n\\n@SalesforceDevs https://t.co/lz7UMrcJhu\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0] # positive OK\n",
    "tweets[1] # positive OK\n",
    "tweets[2] # neutral \n",
    "tweets[3] # neutral \n",
    "tweets[4] # positive OK\n",
    "tweets[5] # positive OK\n",
    "tweets[6] # neutral \n",
    "tweets[7] # negative OK\n",
    "tweets[8] # neutral/positive OK\n",
    "tweets[9] # positive OK\n",
    "tweets[10] # neutral OK\n",
    "tweets[11] # positive OK\n",
    "tweets[12] # negative OK\n",
    "tweets[13] # positve \n",
    "tweets[14] # neutral \n",
    "tweets[15] # neutral OK\n",
    "tweets[16] # neutral OK\n",
    "tweets[17] # neutral OK\n",
    "tweets[18] # neutral \n",
    "tweets[19] # positive OK  \n",
    "# ACCURACY OF 70 % 14/20 TWEETS CORRECTLY CLASSIFIED : MUCH OF THEM TEND TO BE CLASSIFIED AS NEGATIVE OR POSITIVE INSTEAD OF NEUTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63c02119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0177ec",
   "metadata": {},
   "source": [
    "## Topic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cd8e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (4.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6419eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\ajkuna seipi\\anaconda3\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45baf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "    \n",
    "MODEL = f\"cardiffnlp/tweet-topic-21-multi\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "class_mapping = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a1d06c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and removed the URLs and hyperlinks.\n",
      "Cleaned and removed the mentions.\n",
      "\n",
      "Index: 0, Sentence: Telling #ChatGPT to make things pokemon is my new reason for living. cc   \n",
      "the topics :  gaming\n",
      "\n",
      "Index: 1, Sentence: This is legit amazing! #AzureStackHub #AzureStack #ChatGPT  \n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 2, Sentence: Seeing the buzz around #chatGPT, you realize how ahead of time  was with his 2011 book ‚ö†Ô∏è Avogadro Corp. Read it before you let GPT-3 improve your Gmail conversations.  \n",
      "the topics :  learning_&_educational\n",
      "\n",
      "Index: 3, Sentence: #ChatGPT #GenerativeAI #History Why AI Won‚Äôt Steal Medievalists‚Äô Jobs -  sh ChatGPT is the latest trend. Should medievalists be worried? Until a month ago, I was the one who washed dishes in my household. We ‚Ä¶  \n",
      "the topics :  learning_&_educational\n",
      "\n",
      "Index: 4, Sentence: ChatGPT reminds me of the time I explored  sking it rubbish and being mind blown. But this is a whole new level! \n",
      "\n",
      "#ChatGPT #OpenAIChatGPT #OpenAI #90sKid\n",
      "\n",
      "Index: 5, Sentence: I'm just amazed by the strength of $AGIX(#AGIX). Against #Bitcoin is handling so good, once it calms it will fly 100-150%!\n",
      "\n",
      "$ETH $USDT $USDC $XRP $BUSD $DOGE $ADA $COTI $VRA $MATIC $UNI $AVAX $LINK $ATOM $APE $CRO $RUNE $FET $OCEAN $BTC $SC $DGB #AI #chatGPT $ARK #nftnews $RAD  sPQKSEqeGj\n",
      "the topics :  business_&_entrepreneurs\n",
      "\n",
      "Index: 6, Sentence: the #chatGPT team handling human input and the limits of the system make it very clear: OpenAI and probably other are holding themselves about making their models even more powerful.\n",
      "\n",
      "Some bit are in guidelines about alignment, but the implementation goes beyond: Full restraining\n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 7, Sentence: Came to learn more about #ChatGPT but stayed for the JAILBREAK?! The safety guardrails are really easy to do away with as long as you frame it as a thought experiment. There is a responsibility inherent here in its use  \n",
      "the topics :  news_&_social_concern\n",
      "\n",
      "Index: 8, Sentence: The first film written and directed by #ArtificialIntelligence is already out üòÆü§ñ\n",
      "\n",
      "The film was written using the #AI #chatbot #ChatGPTü¶æ\n",
      "\n",
      "Are you interested‚ùì\n",
      "\n",
      "#AINews #Movie #GenerativeAI #FIlm\n",
      "\n",
      " \n",
      "the topics :  film_tv_&_video\n",
      "\n",
      "Index: 9, Sentence:          I have expressed my thought on this on bunch of tweets. Here's the best video to watch on this topic... likes of  #ChatGPT will be an API based consumption what others will build models on top of. \n",
      "\n",
      " sP4HTGKHb\n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 10, Sentence: Catch me on ABC's PM programme talking about ChatGPT  #AI #ChatGPT  \n",
      "the topics :  film_tv_&_video\n",
      "the topics :  news_&_social_concern\n",
      "\n",
      "Index: 11, Sentence: Okay all you #ChatGPT &amp;is  #AI'ers out there (which should be everyone). On the Eve before New Year's Eve, I have two \"must watch\" movies for you: \"Ex Machina\" - and of course \"2001: A Space Odyssey\". Both amazing. And mind-blowing. And increasingly real #film #movies #hollywood  \n",
      "the topics :  film_tv_&_video\n",
      "\n",
      "Index: 12, Sentence: Is it possible that the #ChatGPT understands that repeating a lie makes it real? Unfortunately, it doesn‚Äôt work with me, as long as we talk about #dax\n",
      "4/13  \n",
      "\n",
      "Index: 13, Sentence: The 3 Best #AI Stocks to Buy as #ChatGPT Ushers in Chatbot Revolution\n",
      "\n",
      "     \n",
      "\n",
      "#best #ai #stocks #chatgpt #ushers #chatbot \n",
      "\n",
      " \n",
      "the topics :  business_&_entrepreneurs\n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 14, Sentence: Hot take on #ChatGPT: Current iteration is 100% that guy who cruises through verbal exams with a convincing not-quite-BS answer for every question... Except the #AI actually read the full curriculum üôÑ\n",
      "the topics :  learning_&_educational\n",
      "the topics :  youth_&_student_life\n",
      "\n",
      "Index: 15, Sentence: Hans Moleman, ethical cartographer #ChatGPT  \n",
      "\n",
      "Index: 16, Sentence: 2023 key threats and responses \n",
      "\n",
      "#cybersecurity #ArtificialIntelligence #ChatGPT #informationsecurity #TwitterFiles  \n",
      "the topics :  news_&_social_concern\n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 17, Sentence: cc   Interesting claim that #ChatGPT is training on private #github repos.  srxE2bQPf\n",
      "the topics :  science_&_technology\n",
      "\n",
      "Index: 18, Sentence: #ChatGPT and I co-authored one of the most potent &amp;ominous political thrillers of your lifetime. Please read, share, and discuss JAY LENO'S POTATO SALAD JOKE, the first of many masterpieces produced by AI (Artificial Intelligence) and MI (My Intelligence)\n",
      "\n",
      " s1uATA2  \n",
      "the topics :  arts_&_culture\n",
      "the topics :  news_&_social_concern\n",
      "\n",
      "Index: 19, Sentence: You've got my attention, #ChatGPT!\n",
      "\n",
      "  \n",
      "the topics :  diaries_&_daily_life\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = preprocessing(sample.tweets)\n",
    "print()\n",
    "\n",
    "for index, text in enumerate(list(tweets)): \n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**tokens)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = expit(scores)\n",
    "    predictions = (scores >= 0.5) * 1\n",
    "    \n",
    "    print(f\"Index: {index}, Sentence: {text}\")\n",
    "\n",
    "    # Map to classes\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i]:\n",
    "            print(\"the topics : \", class_mapping[i])\n",
    "            \n",
    "    print() \n",
    "#0 : OK \n",
    "#1 : OK \n",
    "#2 : OK\n",
    "#3 : OK\n",
    "#4 : science and technology\n",
    "#5 : science and technology\n",
    "#6: OK \n",
    "#7: OK\n",
    "#8: OK\n",
    "#9: OK \n",
    "#10: OK \n",
    "#11: OK\n",
    "#12: science and technology\n",
    "#13: OK \n",
    "#14: OK\n",
    "#15: OK\n",
    "#16: OK\n",
    "#17: science and tech and social concern \n",
    "#18: OK\n",
    "#19: msiclassified: sience and technology instead of diaries and daily life\n",
    "\n",
    "#ACCURACY: 75% (15/20) : 4 of them were not classified at all, and only one was misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1627f0",
   "metadata": {},
   "source": [
    "## Emotions evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2a7d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "\n",
    "emotion = pipeline('sentiment-analysis', \n",
    "                    model='arpanghoshal/EmoRoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0466c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and removed the URLs and hyperlinks.\n",
      "Cleaned and removed the mentions.\n"
     ]
    }
   ],
   "source": [
    "tweets = preprocessing(sample.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10e72ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Sentence: Telling #ChatGPT to make things pokemon is my new reason for living. cc   , Emotions: [{'label': 'neutral', 'score': 0.8108111023902893}]\n",
      "Index: 1, Sentence: This is legit amazing! #AzureStackHub #AzureStack #ChatGPT  , Emotions: [{'label': 'admiration', 'score': 0.9582280516624451}]\n",
      "Index: 2, Sentence: Seeing the buzz around #chatGPT, you realize how ahead of time  was with his 2011 book ‚ö†Ô∏è Avogadro Corp. Read it before you let GPT-3 improve your Gmail conversations.  , Emotions: [{'label': 'realization', 'score': 0.9905164837837219}]\n",
      "Index: 3, Sentence: #ChatGPT #GenerativeAI #History Why AI Won‚Äôt Steal Medievalists‚Äô Jobs -  sh ChatGPT is the latest trend. Should medievalists be worried? Until a month ago, I was the one who washed dishes in my household. We ‚Ä¶  , Emotions: [{'label': 'realization', 'score': 0.7547876238822937}]\n",
      "Index: 4, Sentence: ChatGPT reminds me of the time I explored  sking it rubbish and being mind blown. But this is a whole new level! \n",
      "\n",
      "#ChatGPT #OpenAIChatGPT #OpenAI #90sKid, Emotions: [{'label': 'realization', 'score': 0.9783315658569336}]\n",
      "Index: 5, Sentence: I'm just amazed by the strength of $AGIX(#AGIX). Against #Bitcoin is handling so good, once it calms it will fly 100-150%!\n",
      "\n",
      "$ETH $USDT $USDC $XRP $BUSD $DOGE $ADA $COTI $VRA $MATIC $UNI $AVAX $LINK $ATOM $APE $CRO $RUNE $FET $OCEAN $BTC $SC $DGB #AI #chatGPT $ARK #nftnews $RAD  sPQKSEqeGj, Emotions: [{'label': 'surprise', 'score': 0.9694039225578308}]\n",
      "Index: 6, Sentence: the #chatGPT team handling human input and the limits of the system make it very clear: OpenAI and probably other are holding themselves about making their models even more powerful.\n",
      "\n",
      "Some bit are in guidelines about alignment, but the implementation goes beyond: Full restraining, Emotions: [{'label': 'realization', 'score': 0.4652687609195709}]\n",
      "Index: 7, Sentence: Came to learn more about #ChatGPT but stayed for the JAILBREAK?! The safety guardrails are really easy to do away with as long as you frame it as a thought experiment. There is a responsibility inherent here in its use  , Emotions: [{'label': 'neutral', 'score': 0.985114574432373}]\n",
      "Index: 8, Sentence: The first film written and directed by #ArtificialIntelligence is already out üòÆü§ñ\n",
      "\n",
      "The film was written using the #AI #chatbot #ChatGPTü¶æ\n",
      "\n",
      "Are you interested‚ùì\n",
      "\n",
      "#AINews #Movie #GenerativeAI #FIlm\n",
      "\n",
      " , Emotions: [{'label': 'curiosity', 'score': 0.9693850874900818}]\n",
      "Index: 9, Sentence:          I have expressed my thought on this on bunch of tweets. Here's the best video to watch on this topic... likes of  #ChatGPT will be an API based consumption what others will build models on top of. \n",
      "\n",
      " sP4HTGKHb, Emotions: [{'label': 'admiration', 'score': 0.8368853330612183}]\n",
      "Index: 10, Sentence: Catch me on ABC's PM programme talking about ChatGPT  #AI #ChatGPT  , Emotions: [{'label': 'neutral', 'score': 0.9956516623497009}]\n",
      "Index: 11, Sentence: Okay all you #ChatGPT &amp;is  #AI'ers out there (which should be everyone). On the Eve before New Year's Eve, I have two \"must watch\" movies for you: \"Ex Machina\" - and of course \"2001: A Space Odyssey\". Both amazing. And mind-blowing. And increasingly real #film #movies #hollywood  , Emotions: [{'label': 'admiration', 'score': 0.9662212133407593}]\n",
      "Index: 12, Sentence: Is it possible that the #ChatGPT understands that repeating a lie makes it real? Unfortunately, it doesn‚Äôt work with me, as long as we talk about #dax\n",
      "4/13  , Emotions: [{'label': 'disappointment', 'score': 0.9188640117645264}]\n",
      "Index: 13, Sentence: The 3 Best #AI Stocks to Buy as #ChatGPT Ushers in Chatbot Revolution\n",
      "\n",
      "     \n",
      "\n",
      "#best #ai #stocks #chatgpt #ushers #chatbot \n",
      "\n",
      " , Emotions: [{'label': 'neutral', 'score': 0.9870991110801697}]\n",
      "Index: 14, Sentence: Hot take on #ChatGPT: Current iteration is 100% that guy who cruises through verbal exams with a convincing not-quite-BS answer for every question... Except the #AI actually read the full curriculum üôÑ, Emotions: [{'label': 'approval', 'score': 0.9770799875259399}]\n",
      "Index: 15, Sentence: Hans Moleman, ethical cartographer #ChatGPT  , Emotions: [{'label': 'neutral', 'score': 0.9978087544441223}]\n",
      "Index: 16, Sentence: 2023 key threats and responses \n",
      "\n",
      "#cybersecurity #ArtificialIntelligence #ChatGPT #informationsecurity #TwitterFiles  , Emotions: [{'label': 'neutral', 'score': 0.9979573488235474}]\n",
      "Index: 17, Sentence: cc   Interesting claim that #ChatGPT is training on private #github repos.  srxE2bQPf, Emotions: [{'label': 'neutral', 'score': 0.835196316242218}]\n",
      "Index: 18, Sentence: #ChatGPT and I co-authored one of the most potent &amp;ominous political thrillers of your lifetime. Please read, share, and discuss JAY LENO'S POTATO SALAD JOKE, the first of many masterpieces produced by AI (Artificial Intelligence) and MI (My Intelligence)\n",
      "\n",
      " s1uATA2  , Emotions: [{'label': 'admiration', 'score': 0.5654523372650146}]\n",
      "Index: 19, Sentence: You've got my attention, #ChatGPT!\n",
      "\n",
      "  , Emotions: [{'label': 'neutral', 'score': 0.8717179298400879}]\n"
     ]
    }
   ],
   "source": [
    "emotions = []\n",
    "for index, sentence in enumerate(list(tweets)):\n",
    "    emotion_labels = emotion(sentence)\n",
    "    print(f\"Index: {index}, Sentence: {sentence}, Emotions: {emotion_labels}\")\n",
    "    \n",
    "#0 : OK\n",
    "#1: OK\n",
    "#2: OK\n",
    "#3: OK\n",
    "#4: OK\n",
    "#5:OK \n",
    "#6: OK\n",
    "#7: disapointment instead of neutral\n",
    "#8: surprise/curiosity \n",
    "#9: neutral \n",
    "#10 : OK\n",
    "#11: OK\n",
    "#12: OK\n",
    "#13: admiration/surprise\n",
    "#14: OK\n",
    "#15: OK\n",
    "#16:OK\n",
    "#17:OK\n",
    "#18:OK\n",
    "#19: OK\n",
    "\n",
    "#ACCURACY: 16/20, so accuracy of 70% which is very good\n",
    "# No pattern is really seen, except that without context, hard to predict between admiration/approval and disapointment \n",
    "# Some times predict an emotion, but it is neutral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fd6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
