{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34062d6",
   "metadata": {},
   "source": [
    "# Analysis of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00473a",
   "metadata": {},
   "source": [
    "### Research question: What is the impact of the emerging of AI on the population based on tweets \n",
    "#### Analysis: Sentiment Analysis through NLP, focus on ChatGPT\n",
    "- Categorize tweets: positive, negative, neutral \n",
    "- Frequency of words used, what type of words\n",
    "- Evolution of the sentiment analysis: from the beginning of the release of ChatGPT until recently \n",
    "- Fequency of tweets made about AI (mean of tweets per person) \n",
    "- Try to work with threads (to be continued...)\n",
    "- Categorize tweets to workers, students, reasearchers (professors) and see if the sentiment analysis is different for these categories \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5f601",
   "metadata": {},
   "source": [
    "### Some references for the sentiment analysis\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/\n",
    "- https://huggingface.co/blog/sentiment-analysis-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdad096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65a82f",
   "metadata": {},
   "source": [
    "## Exploratory analysis with labeled dataset\n",
    "* dataset contains only english tweets\n",
    "* tweets about ChatGPT gathered for a month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32675764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sentiment.csv', usecols=['tweets','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9869d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195068</th>\n",
       "      <td>News about https://t.co/jn2ucvZO1g!  Wordle, C...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55694</th>\n",
       "      <td>I wonder how long before the first Ecology opi...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18167</th>\n",
       "      <td>Future for creators is going to be incredibleüèÜ...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79322</th>\n",
       "      <td>Why do women in marriage/relationships cheat?\\...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66030</th>\n",
       "      <td>#ChatGPT is an atheist https://t.co/LdYs4pBnLp</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets labels\n",
       "195068  News about https://t.co/jn2ucvZO1g!  Wordle, C...    bad\n",
       "55694   I wonder how long before the first Ecology opi...    bad\n",
       "18167   Future for creators is going to be incredibleüèÜ...    bad\n",
       "79322   Why do women in marriage/relationships cheat?\\...    bad\n",
       "66030      #ChatGPT is an atheist https://t.co/LdYs4pBnLp    bad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4dbef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweets', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550eefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is 219294\n"
     ]
    }
   ],
   "source": [
    "print(\"length of data is\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8793169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219294, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4114fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets    object\n",
       "labels    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb5156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219289</th>\n",
       "      <td>Other Software Projects Are Now Trying to Repl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219290</th>\n",
       "      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219291</th>\n",
       "      <td>chatgpt is being disassembled until it can onl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219292</th>\n",
       "      <td>2023 predictions by #chatGPT. Nothing really s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219293</th>\n",
       "      <td>From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  labels\n",
       "219289  Other Software Projects Are Now Trying to Repl...       1\n",
       "219290  I asked #ChatGPT to write a #NYE Joke for SEOs...       0\n",
       "219291  chatgpt is being disassembled until it can onl...       1\n",
       "219292  2023 predictions by #chatGPT. Nothing really s...       1\n",
       "219293   From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels = df.labels.replace('bad', 1)\n",
    "df.labels = df.labels.replace('neutral', 0)\n",
    "df.labels = df.labels.replace('good', 0)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad27a649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  labels\n",
       "0  ChatGPT: Optimizing Language Models for Dialog...       0\n",
       "1  Try talking with ChatGPT, our new AI system wh...       0\n",
       "2  ChatGPT: Optimizing Language Models for Dialog...       0\n",
       "3  THRILLED to share that ChatGPT, our new model ...       0\n",
       "4  As of 2 minutes ago, @OpenAI released their ne...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872fa525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125880</th>\n",
       "      <td>chatGPT killer use case confirmed https://t.co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35008</th>\n",
       "      <td>I asked ChatGPT to write about itself in my st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105806</th>\n",
       "      <td>\"Are you ready for a wild ride? The Bearded Ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131595</th>\n",
       "      <td>As someone who has personally used the chatGPT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200667</th>\n",
       "      <td>Sabine got me thinking of G√∂del's incompletene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  labels\n",
       "125880  chatGPT killer use case confirmed https://t.co...       1\n",
       "35008   I asked ChatGPT to write about itself in my st...       1\n",
       "105806  \"Are you ready for a wild ride? The Bearded Ti...       0\n",
       "131595  As someone who has personally used the chatGPT...       0\n",
       "200667  Sabine got me thinking of G√∂del's incompletene...       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8b141",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ebe5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweets_train, tweets_test, target_train, target_test = train_test_split(df.tweets,df.labels,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249d3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = tweets_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751c439",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceab60ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    other software projects are now trying to repl...\n",
       "219290    i asked #chatgpt to write a #nye joke for seos...\n",
       "219291    chatgpt is being disassembled until it can onl...\n",
       "219292    2023 predictions by #chatgpt. nothing really s...\n",
       "219293                                                  NaN\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].str.lower()\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3294a373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    chatgpt: optimizing language models dialogue h...\n",
       "1                                                  nan\n",
       "2    chatgpt: optimizing language models dialogue h...\n",
       "3                                                  nan\n",
       "4    2 minutes ago, @openai released new chatgpt. \\...\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining set containing all stopwords in english\n",
    "\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# cleaning and removing the above stop words list from the tweet text\n",
    "STOPWORDS = set(stopwordlist)\n",
    "\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda text: cleaning_stopwords(text))\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc4957c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                                                  nan\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing punctuations \n",
    "\n",
    "import string\n",
    "\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweets']= df['tweets'].apply(lambda x: cleaning_punctuations(x))\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a674334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                                                  nan\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing repeating characters\n",
    "\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: cleaning_repeating_char(x))\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e88551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289          software projects trying replicate chatgpt \n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                                                  nan\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing URLs\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: cleaning_URLs(x))\n",
    "\n",
    "def remove_hyperlink(word):\n",
    "    return re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: remove_hyperlink(x))\n",
    "\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f1379820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289          software projects trying replicate chatgpt \n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                                  chatgpt neat stuff \n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing mentions \n",
    "\n",
    "def remove_mentions(word):\n",
    "    return re.sub(r\"@\\S+\", \"\", word)\n",
    "\n",
    "df['tweets'] = df['tweets'].apply(lambda x: remove_mentions(x))\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "95cdb5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ajkuna\n",
      "[nltk_data]     Seipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2bac0078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289     [software, projects, trying, replicate, chatgpt]\n",
       "219290    [asked, chatgpt, write, nye, joke, seos, deliv...\n",
       "219291                   [chatgpt, disassembled, dissemble]\n",
       "219292    [2023, predictions, chatgpt, nothing, really, ...\n",
       "219293                               [chatgpt, neat, stuff]\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization of tweet text : process of splitting text into \n",
    "# smaller chuncks, called tokens \n",
    "# each tokey is an input to the machine learning algorithm as a featue\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "test2 = df['tweets'].apply(word_tokenize)\n",
    "test2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8438b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "23c0f2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289                   softwar project tri replic chatgpt\n",
       "219290    ask chatgpt write nye joke seo deliv nnwhi seo...\n",
       "219291                          chatgpt disassembl dissembl\n",
       "219292    2023 predict chatgpt noth realli specif trend ...\n",
       "219293                                   chatgpt neat stuff\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying stemming : process of removing and replacing suffixes from a token\n",
    "# to obtain the root or base form of the word \n",
    "\n",
    "# Porter stemmer is a widely used stemming technique \n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text])\n",
    "\n",
    "\n",
    "test = df['tweets'].apply(lambda text: stem_words(text))\n",
    "\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "feb03d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ec0f3",
   "metadata": {},
   "source": [
    "## Word embedding techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "507125b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 69.6 GiB for an array with shape (219294, 42608) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6884\\1613564107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtweets_processed\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 69.6 GiB for an array with shape (219294, 42608) and data type int64"
     ]
    }
   ],
   "source": [
    "# use of Bag of Words as a word embedding technique \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(min_df = 2, max_features = 100000)\n",
    "\n",
    "bow.fit(test)\n",
    "\n",
    "tweets_processed =bow.transform(test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5792bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec embedding technique\n",
    "\n",
    "import gensim\n",
    "\n",
    "tokenize = test.apply(lambda x: x.split())\n",
    "w2vec_model = gensim.models.Word2Vec(tokenize, min_count = 1, vector_size = 100, window = 5, sg = 1)\n",
    "w2vec_model.train(tokenize, total_examples = len(test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c229c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b3897",
   "metadata": {},
   "source": [
    "### Model Fitting \n",
    "\n",
    "* Logistic Regression: highly efficient and simple as classification applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(tweets_train, target_train)\n",
    "\n",
    "# training the model\n",
    "prediction = model.predict_proba(tweets_test)\n",
    "# predicting on the test set\n",
    "\n",
    "prediction_int = prediction[:,1] >= 0.3 # if prediction is greater than or equal to 0.3 then 1 else 0\n",
    "prediction_int = prediction_int.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792bf32",
   "metadata": {},
   "source": [
    "## Analysis of dataset of first month of launching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ab62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/chatgptfirst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed3542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>country</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1598014056790622225</td>\n",
       "      <td>2022-11-30 18:00:15+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598014522098208769</td>\n",
       "      <td>2022-11-30 18:02:06+00:00</td>\n",
       "      <td>12179</td>\n",
       "      <td>889</td>\n",
       "      <td>1130</td>\n",
       "      <td>3252</td>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1598014741527527435</td>\n",
       "      <td>2022-11-30 18:02:58+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1598015493666766849</td>\n",
       "      <td>2022-11-30 18:05:58+00:00</td>\n",
       "      <td>561</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1598015509420994561</td>\n",
       "      <td>2022-11-30 18:06:01+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                 created_at  like_count  quote_count  \\\n",
       "0  1598014056790622225  2022-11-30 18:00:15+00:00           2            0   \n",
       "1  1598014522098208769  2022-11-30 18:02:06+00:00       12179          889   \n",
       "2  1598014741527527435  2022-11-30 18:02:58+00:00           2            0   \n",
       "3  1598015493666766849  2022-11-30 18:05:58+00:00         561            8   \n",
       "4  1598015509420994561  2022-11-30 18:06:01+00:00           1            0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0            0              0   \n",
       "1         1130           3252   \n",
       "2            0              1   \n",
       "3           25             66   \n",
       "4            0              0   \n",
       "\n",
       "                                               tweet country  \\\n",
       "0  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "1  Try talking with ChatGPT, our new AI system wh...     NaN   \n",
       "2  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "3  THRILLED to share that ChatGPT, our new model ...     NaN   \n",
       "4  As of 2 minutes ago, @OpenAI released their ne...     NaN   \n",
       "\n",
       "                                         photo_url city country_code  \n",
       "0                                              NaN  NaN          NaN  \n",
       "1                                              NaN  NaN          NaN  \n",
       "2  https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg  NaN          NaN  \n",
       "3  https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg  NaN          NaN  \n",
       "4                                              NaN  NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723957ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4937d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81326     There's a whole genre on bilibili teaching you...\n",
       "113541                    Okay this ChatGPT AI tool.. wow!!\n",
       "171849    I wish chatGPT existed when I was in college. ...\n",
       "67417     What is ChatGPT, the viral social media AI? ‚Äì ...\n",
       "145738    Check out my latest blog post, where I see if ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a523aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN value\n",
    "\n",
    "df.isnull().values.any()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ceb60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219294"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72dbcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ChatGPT: Optimizing Language Models for Dialog...\n",
       "1    Try talking with ChatGPT, our new AI system wh...\n",
       "2    ChatGPT: Optimizing Language Models for Dialog...\n",
       "3    THRILLED to share that ChatGPT, our new model ...\n",
       "4    As of 2 minutes ago, @OpenAI released their ne...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
