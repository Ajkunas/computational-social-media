{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e08eff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# remove english stopwords with the help of the gensim library \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8db5af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "# cleaning and removing URLs\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "def remove_hyperlink(word):\n",
    "    return re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "# cleaning and removing mentions \n",
    "def remove_mentions(word):\n",
    "    return re.sub(r\"@\\S+\", \"\", word)\n",
    "\n",
    "# removing emojis \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# cleaning and removing repeating characters\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lematize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbad9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    # lower cases \n",
    "    df = df.str.lower()\n",
    "    print(\"Text of tweets transformed to lower cases.\")\n",
    "    \n",
    "    # remove english stopwords with the help of the gensim library \n",
    "    df = df.apply(lambda text: remove_stopwords(text))\n",
    "    print(\"Removed stopwords from the text of tweets.\")\n",
    "    \n",
    "    #cleaning and removing punctuation\n",
    "    df = df.apply(lambda x: cleaning_punctuations(x))\n",
    "    print(\"Cleaned and removed the punctuations.\")\n",
    "    \n",
    "    # cleaning and removing URLs\n",
    "    df = df.apply(lambda x: cleaning_URLs(x))\n",
    "    df = df.apply(lambda x: remove_hyperlink(x))\n",
    "    print(\"Cleaned and removed the URLs and hyperlinks.\")\n",
    "    \n",
    "    # cleaning and removing mentions \n",
    "    df = df.apply(lambda x: remove_mentions(x))\n",
    "    print(\"Cleaned and removed the mentions.\")\n",
    "    \n",
    "    # removing emojis \n",
    "    df = df.apply(lambda x: emoji_pattern.sub(r'', x))\n",
    "    print(\"Removed the emojis.\")\n",
    "    \n",
    "    # remove numbers \n",
    "    df = df.apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "    print(\"Removed the numbers.\")\n",
    "    \n",
    "    # Text normalization : tokenize the tweets \n",
    "    # split tweets of text into tokens (individual words of terms)\n",
    "    tokenize_tweets = df.apply(lambda x: x.split())\n",
    "    print(\"Tokenized the text.\")\n",
    "    \n",
    "    # Normalization: use of PorterStemmer()\n",
    "    tokenize_tweets = tokenize_tweets.apply(lambda text: lematize_words(text))\n",
    "    print(\"Normalized the text.\")\n",
    "    \n",
    "    # write new csv file containing the preprocessed dataset\n",
    "    return tokenize_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "040cb593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "df = pd.read_csv('datasets/sample_user_descr.csv', usecols=['user_name','user_description','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12c7e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speak</td>\n",
       "      <td>Join 20,000+ researchers and marketers using S...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CanGPT</td>\n",
       "      <td>I tweet about #AI #ChatGPT #Web3 üöÄüöÄ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best MidJourneyAI Generated Artü§ñüé®</td>\n",
       "      <td>follow my twitter account if you like the cont...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NikPeachey</td>\n",
       "      <td>Co-founder https://t.co/6o0xPcZuc4. Award-Winn...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Webrpoint</td>\n",
       "      <td>We provide the solutions on Web Technology by ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Dennis Kirwan</td>\n",
       "      <td>Ever since I can remember, my curious mind has...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Kamran (Shuja Kami)</td>\n",
       "      <td>An #SMM and an affiliate marketing guy. #Blogg...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Hady Ghandour</td>\n",
       "      <td>Experienced Telecom/ICT professional, @AUBalum...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>·ûµ</td>\n",
       "      <td>ùë∞ ùíâùíÇùíóùíÜ ùíèùíêùíïùíâùíäùíèùíà ùíïùíê ùíÖùíÜùíÑùíçùíÇùíìùíÜ. \\nhttps://t.co/RBEW...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>BOBJERYSARAGIH</td>\n",
       "      <td>Infuencer crypto project AventCoin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_name  \\\n",
       "0                                Speak   \n",
       "1                               CanGPT   \n",
       "2    Best MidJourneyAI Generated Artü§ñüé®   \n",
       "3                           NikPeachey   \n",
       "4                            Webrpoint   \n",
       "..                                 ...   \n",
       "195                      Dennis Kirwan   \n",
       "196                Kamran (Shuja Kami)   \n",
       "197                      Hady Ghandour   \n",
       "198                                  ·ûµ   \n",
       "199                     BOBJERYSARAGIH   \n",
       "\n",
       "                                      user_description  label  \n",
       "0    Join 20,000+ researchers and marketers using S...    0.0  \n",
       "1                  I tweet about #AI #ChatGPT #Web3 üöÄüöÄ    0.0  \n",
       "2    follow my twitter account if you like the cont...    0.0  \n",
       "3    Co-founder https://t.co/6o0xPcZuc4. Award-Winn...    0.0  \n",
       "4    We provide the solutions on Web Technology by ...    0.0  \n",
       "..                                                 ...    ...  \n",
       "195  Ever since I can remember, my curious mind has...    0.0  \n",
       "196  An #SMM and an affiliate marketing guy. #Blogg...    0.0  \n",
       "197  Experienced Telecom/ICT professional, @AUBalum...    0.0  \n",
       "198  ùë∞ ùíâùíÇùíóùíÜ ùíèùíêùíïùíâùíäùíèùíà ùíïùíê ùíÖùíÜùíÑùíçùíÇùíìùíÜ. \\nhttps://t.co/RBEW...    0.0  \n",
       "199                 Infuencer crypto project AventCoin    0.0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1827a9",
   "metadata": {},
   "source": [
    "## Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b035b2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    177\n",
       "1.0     18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SCIENTIST/RESEARCHER/ENGINEER : 1\n",
    "# NOT SCIENTIST : 0\n",
    "\n",
    "df.label.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "868adfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name           0\n",
       "user_description    0\n",
       "label               5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce978ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdd423",
   "metadata": {},
   "source": [
    "## Balancing data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafb224",
   "metadata": {},
   "source": [
    "In our case, we have relatively very few datas labeled with 1 than those labeled with 0. We decide to upsample the minority class for a better training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a773b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = df[df.label == 0]\n",
    "minority_class = df[df.label == 1]\n",
    "\n",
    "# Upsample the minority class\n",
    "upsampled_minority = resample(minority_class, replace=True, n_samples=len(majority_class))\n",
    "\n",
    "# Combine the upsampled minority class with the majority class\n",
    "balanced_data = pd.concat([majority_class, upsampled_minority])\n",
    "\n",
    "# Shuffle the data\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76c5753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Melvin</td>\n",
       "      <td>Works as Machine Learning Engineer. Solopreneu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Aaron Junker</td>\n",
       "      <td>Mastodon: @AaronJunker@phpc.social</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Yuriy Yuzifovich</td>\n",
       "      <td>Technology enthusiast. Ex-Nominum, Ex-@Akamai....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Aakash Chowkase</td>\n",
       "      <td>Post-doc @UCBerkeley @GreaterGoodSC. PhD in Ed...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Aimie Sibson</td>\n",
       "      <td>Co-founder &amp; CEO Hero</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>pipik_roman</td>\n",
       "      <td>Software Dev. at https://t.co/Iw3EvbMYdl, husb...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Wes üá®üá¶‚úåÔ∏èüá∫üá¶</td>\n",
       "      <td>I'm an IT manager in my early 40's. To be hone...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Natarajan Ganesan, PhD</td>\n",
       "      <td>Scientist, Entrepreneur, Educator. Tweets are ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lon Baker</td>\n",
       "      <td>Multi-talented entrepreneur, engineer, content...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Rampage</td>\n",
       "      <td>Investing in @rockaway_x, ex-ITSec software en...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_name  \\\n",
       "155                  Melvin   \n",
       "45             Aaron Junker   \n",
       "135        Yuriy Yuzifovich   \n",
       "103         Aakash Chowkase   \n",
       "62             Aimie Sibson   \n",
       "..                      ...   \n",
       "80              pipik_roman   \n",
       "119              Wes üá®üá¶‚úåÔ∏èüá∫üá¶   \n",
       "116  Natarajan Ganesan, PhD   \n",
       "55                Lon Baker   \n",
       "114                 Rampage   \n",
       "\n",
       "                                      user_description  label  \n",
       "155  Works as Machine Learning Engineer. Solopreneu...    1.0  \n",
       "45                  Mastodon: @AaronJunker@phpc.social    0.0  \n",
       "135  Technology enthusiast. Ex-Nominum, Ex-@Akamai....    1.0  \n",
       "103  Post-doc @UCBerkeley @GreaterGoodSC. PhD in Ed...    1.0  \n",
       "62                               Co-founder & CEO Hero    0.0  \n",
       "..                                                 ...    ...  \n",
       "80   Software Dev. at https://t.co/Iw3EvbMYdl, husb...    0.0  \n",
       "119  I'm an IT manager in my early 40's. To be hone...    0.0  \n",
       "116  Scientist, Entrepreneur, Educator. Tweets are ...    1.0  \n",
       "55   Multi-talented entrepreneur, engineer, content...    1.0  \n",
       "114  Investing in @rockaway_x, ex-ITSec software en...    0.0  \n",
       "\n",
       "[354 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b337a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "974328ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_name           0\n",
       "user_description    0\n",
       "label               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeb040a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155    1.0\n",
       "45     0.0\n",
       "135    1.0\n",
       "103    1.0\n",
       "62     0.0\n",
       "      ... \n",
       "80     0.0\n",
       "119    0.0\n",
       "116    1.0\n",
       "55     1.0\n",
       "114    0.0\n",
       "Name: label, Length: 354, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "631d847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.user_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb9c0620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155    Works as Machine Learning Engineer. Solopreneu...\n",
       "45                    Mastodon: @AaronJunker@phpc.social\n",
       "135    Technology enthusiast. Ex-Nominum, Ex-@Akamai....\n",
       "103    Post-doc @UCBerkeley @GreaterGoodSC. PhD in Ed...\n",
       "62                                 Co-founder & CEO Hero\n",
       "                             ...                        \n",
       "80     Software Dev. at https://t.co/Iw3EvbMYdl, husb...\n",
       "119    I'm an IT manager in my early 40's. To be hone...\n",
       "116    Scientist, Entrepreneur, Educator. Tweets are ...\n",
       "55     Multi-talented entrepreneur, engineer, content...\n",
       "114    Investing in @rockaway_x, ex-ITSec software en...\n",
       "Name: user_description, Length: 354, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc7f1c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN value\n",
    "temp.isnull().values.any()\n",
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cf5df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text of tweets transformed to lower cases.\n",
      "Removed stopwords from the text of tweets.\n",
      "Cleaned and removed the punctuations.\n",
      "Cleaned and removed the URLs and hyperlinks.\n",
      "Cleaned and removed the mentions.\n",
      "Removed the emojis.\n",
      "Removed the numbers.\n",
      "Tokenized the text.\n",
      "Normalized the text.\n"
     ]
    }
   ],
   "source": [
    "descr = preprocessing(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "154a49e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155    work machine learning engineer solopreneur eve...\n",
       "45                        mastodon aaronjunkerphpcsocial\n",
       "135    technology enthusiast exnominum exakamai proud...\n",
       "103    postdoc ucberkeley greatergoodsc phd education...\n",
       "62                                    cofounder ceo hero\n",
       "                             ...                        \n",
       "80     software dev husband father catholic christian...\n",
       "119    im manager early s honest gotten crypto sooner...\n",
       "116    scientist entrepreneur educator tweet fleeting...\n",
       "55     multitalented entrepreneur engineer content cr...\n",
       "114    investing rockawayx exitsec software engineer ...\n",
       "Name: user_description, Length: 354, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b218404",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30e4ce",
   "metadata": {},
   "source": [
    "Apply Logistic Regression with W2V embedding (see paper for gender classification based on tweet text https://www.researchgate.net/publication/344003069_Gender_Classification_using_Twitter_Text_Data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfb9390d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46646, 78000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Word2Vec features: \n",
    "tokenize_tweet = descr.apply(lambda x: x.split())\n",
    "\n",
    "model_W2V = gensim.models.Word2Vec(tokenize_tweet, \n",
    "                                   vector_size = 200, # No. of features\n",
    "                                   window =  5, # default window\n",
    "                                   min_count = 2, \n",
    "                                   sg = 1, # 1 for skip-gram model\n",
    "                                   hs = 0,\n",
    "                                   negative = 10, # for negative sampling\n",
    "                                   workers = 2,  # No. of cores\n",
    "                                   seed = 34 )\n",
    "\n",
    "model_W2V.train(tokenize_tweet, total_examples= len(descr), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2463be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 5 times  421\n",
      "sample words  ['ai', 'engineer', 'learning', 'data', 'machine', 'tweet', 'opinion', 'leading', 'science', 'leader', 'scientist', 'passionate', 'educator', 'research', 'entrepreneur', 'system', 'technology', 'innovation', 'prompt', 'work', 'phd', 'microsoft', 'solopreneur', 'investment', 'evening', 'weekend', 'revolution', 'llm', 'education', 'development', 'teacher', 'gpt', 'enthusiast', 'chatgpt', 'tech', 'advocate', 'world', 'content', 'news', 'llmops', 'lead', 'mlops', 'product', 'researcher', 'follow', 'alum', 'help', 'supportjpf', 'agent', 'proud']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(model_W2V.wv.index_to_key)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f58c2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 354/354 [00:00<00:00, 4938.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "vector = []\n",
    "for sent in tqdm(tokenize_tweet):\n",
    "    sent_vec = np.zeros(200)\n",
    "    count = 0\n",
    "    for word in sent: \n",
    "        if word in w2v_words:\n",
    "            vec = model_W2V.wv[word]\n",
    "            sent_vec += vec \n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        sent_vec /= count #normalize\n",
    "    vector.append(sent_vec)\n",
    "    \n",
    "print(len(vector))\n",
    "print(len(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f88788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "x_train_w2v, x_test_w2v, y_train_w2v, y_test_w2v = train_test_split(vector, df.label, test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43fa0b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN value\n",
    "\n",
    "y_train_w2v.isnull().values.any()\n",
    "y_train_w2v.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02e390d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0], 'warm_start': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "#parameters in Logistic Regression\n",
    "param_grid_lr = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "                'warm_start':[True, False]}\n",
    "print(param_grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4db5ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'warm_start': True, 'C': 10.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters for LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "LR_RandomGrid = RandomizedSearchCV(estimator = model_lr, param_distributions = param_grid_lr, cv = 10, verbose=2, n_jobs = 4)\n",
    "LR_RandomGrid.fit(x_train_w2v, y_train_w2v)\n",
    "LR_RandomGrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "272c56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98        60\n",
      "         1.0       0.96      1.00      0.98        47\n",
      "\n",
      "    accuracy                           0.98       107\n",
      "   macro avg       0.98      0.98      0.98       107\n",
      "weighted avg       0.98      0.98      0.98       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "model_lr = LogisticRegression(C=10.0, warm_start=True, max_iter=100, multi_class='auto')\n",
    "model_lr = model_lr.fit(x_train_w2v, y_train_w2v)\n",
    "prediction_lr = model_lr.predict(x_test_w2v)\n",
    "\n",
    "print(classification_report(y_test_w2v, prediction_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e4889d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfe4e52",
   "metadata": {},
   "source": [
    "## Classification of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a421e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "df = pd.read_csv('datasets/sentiment_chatgpt.csv', usecols=['user_description','tweets','label', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fdf83ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_description</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building draftmateai developer author chatgpt ...</td>\n",
       "      <td>happy share draftmateai support day free trial...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nomadic marketing vigilante graphic web design...</td>\n",
       "      <td>integrate chatgpt marketo smart campaign disco...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leading translation management platform locali...</td>\n",
       "      <td>pleased announce new patentpending technology ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engineering leader coach mentor building remot...</td>\n",
       "      <td>starting tire scolded chatgpt slight perceived...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-04-26 13:02:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop learning research develop uild future eyo...</td>\n",
       "      <td>spartajustice it notable wikipedia entry john ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:01:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369265</th>\n",
       "      <td>brain meant processing million tweet post vide...</td>\n",
       "      <td>chatgpt biggest smartest brain world right now...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 17:11:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369266</th>\n",
       "      <td>blockchain enthusiast philanthropist slave jav...</td>\n",
       "      <td>levelsso happy chatgpt team com revolutionary ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:10:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369267</th>\n",
       "      <td>mathematician developer amazon previously geob...</td>\n",
       "      <td>russel chatgpt it funny take long time answer ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-05 17:09:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369268</th>\n",
       "      <td>passionate nature software developer profession</td>\n",
       "      <td>wondering difference jasper chatgpt gpt chatgp...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:08:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369269</th>\n",
       "      <td>postdoc gipplab unigoettingen phd unikonstanz ...</td>\n",
       "      <td>chatgpt similar llm pose challenge academic in...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:08:20+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369270 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_description  \\\n",
       "0       building draftmateai developer author chatgpt ...   \n",
       "1       nomadic marketing vigilante graphic web design...   \n",
       "2       leading translation management platform locali...   \n",
       "3       engineering leader coach mentor building remot...   \n",
       "4       stop learning research develop uild future eyo...   \n",
       "...                                                   ...   \n",
       "369265  brain meant processing million tweet post vide...   \n",
       "369266  blockchain enthusiast philanthropist slave jav...   \n",
       "369267  mathematician developer amazon previously geob...   \n",
       "369268    passionate nature software developer profession   \n",
       "369269  postdoc gipplab unigoettingen phd unikonstanz ...   \n",
       "\n",
       "                                                   tweets    label  \\\n",
       "0       happy share draftmateai support day free trial...  positiv   \n",
       "1       integrate chatgpt marketo smart campaign disco...  positiv   \n",
       "2       pleased announce new patentpending technology ...  positiv   \n",
       "3       starting tire scolded chatgpt slight perceived...  neutral   \n",
       "4       spartajustice it notable wikipedia entry john ...  positiv   \n",
       "...                                                   ...      ...   \n",
       "369265  chatgpt biggest smartest brain world right now...  negativ   \n",
       "369266  levelsso happy chatgpt team com revolutionary ...  positiv   \n",
       "369267  russel chatgpt it funny take long time answer ...  neutral   \n",
       "369268  wondering difference jasper chatgpt gpt chatgp...  positiv   \n",
       "369269  chatgpt similar llm pose challenge academic in...  positiv   \n",
       "\n",
       "                             date  \n",
       "0       2023-04-26 13:02:16+00:00  \n",
       "1       2023-04-26 13:02:06+00:00  \n",
       "2       2023-04-26 13:02:05+00:00  \n",
       "3       2023-04-26 13:02:00+00:00  \n",
       "4       2023-04-26 13:01:52+00:00  \n",
       "...                           ...  \n",
       "369265  2022-12-05 17:11:10+00:00  \n",
       "369266  2022-12-05 17:10:31+00:00  \n",
       "369267  2022-12-05 17:09:04+00:00  \n",
       "369268  2022-12-05 17:08:44+00:00  \n",
       "369269  2022-12-05 17:08:20+00:00  \n",
       "\n",
       "[369270 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "146b1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = df.user_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2d81a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         building draftmateai developer author chatgpt ...\n",
       "1         nomadic marketing vigilante graphic web design...\n",
       "2         leading translation management platform locali...\n",
       "3         engineering leader coach mentor building remot...\n",
       "4         stop learning research develop uild future eyo...\n",
       "                                ...                        \n",
       "369265    brain meant processing million tweet post vide...\n",
       "369266    blockchain enthusiast philanthropist slave jav...\n",
       "369267    mathematician developer amazon previously geob...\n",
       "369268      passionate nature software developer profession\n",
       "369269    postdoc gipplab unigoettingen phd unikonstanz ...\n",
       "Name: user_description, Length: 369270, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0dd431ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN value\n",
    "descr.isnull().values.any()\n",
    "descr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adcb1381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23691661, 72575240)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2Vec features: \n",
    "tokenize_tweet = descr.apply(lambda x: x.split())\n",
    "\n",
    "model_W2V.train(tokenize_tweet, total_examples= len(descr), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3162b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 5 times  421\n",
      "sample words  ['ai', 'engineer', 'learning', 'data', 'machine', 'tweet', 'opinion', 'leading', 'science', 'leader', 'scientist', 'passionate', 'educator', 'research', 'entrepreneur', 'system', 'technology', 'innovation', 'prompt', 'work', 'phd', 'microsoft', 'solopreneur', 'investment', 'evening', 'weekend', 'revolution', 'llm', 'education', 'development', 'teacher', 'gpt', 'enthusiast', 'chatgpt', 'tech', 'advocate', 'world', 'content', 'news', 'llmops', 'lead', 'mlops', 'product', 'researcher', 'follow', 'alum', 'help', 'supportjpf', 'agent', 'proud']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(model_W2V.wv.index_to_key)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c8a0c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369270/369270 [01:17<00:00, 4781.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369270\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector = []\n",
    "for sent in tqdm(tokenize_tweet):\n",
    "    sent_vec = np.zeros(200)\n",
    "    count = 0\n",
    "    for word in sent: \n",
    "        if word in w2v_words:\n",
    "            vec = model_W2V.wv[word]\n",
    "            sent_vec += vec \n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        sent_vec /= count #normalize\n",
    "    vector.append(sent_vec)\n",
    "    \n",
    "print(len(vector))\n",
    "print(len(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "617225ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sc = model_lr.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83565bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d1cebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = {'user_description': df.user_description.values, 'SC': prediction_sc, 'tweets': df.tweets.values, 'label': df.label.values, 'date': df.date.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa129e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "826c5994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_description</th>\n",
       "      <th>SC</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building draftmateai developer author chatgpt ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>happy share draftmateai support day free trial...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nomadic marketing vigilante graphic web design...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>integrate chatgpt marketo smart campaign disco...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leading translation management platform locali...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pleased announce new patentpending technology ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:02:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engineering leader coach mentor building remot...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>starting tire scolded chatgpt slight perceived...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-04-26 13:02:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop learning research develop uild future eyo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>spartajustice it notable wikipedia entry john ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:01:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369265</th>\n",
       "      <td>brain meant processing million tweet post vide...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chatgpt biggest smartest brain world right now...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 17:11:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369266</th>\n",
       "      <td>blockchain enthusiast philanthropist slave jav...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>levelsso happy chatgpt team com revolutionary ...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:10:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369267</th>\n",
       "      <td>mathematician developer amazon previously geob...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>russel chatgpt it funny take long time answer ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-12-05 17:09:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369268</th>\n",
       "      <td>passionate nature software developer profession</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wondering difference jasper chatgpt gpt chatgp...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:08:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369269</th>\n",
       "      <td>postdoc gipplab unigoettingen phd unikonstanz ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chatgpt similar llm pose challenge academic in...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 17:08:20+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369270 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_description   SC  \\\n",
       "0       building draftmateai developer author chatgpt ...  0.0   \n",
       "1       nomadic marketing vigilante graphic web design...  0.0   \n",
       "2       leading translation management platform locali...  0.0   \n",
       "3       engineering leader coach mentor building remot...  0.0   \n",
       "4       stop learning research develop uild future eyo...  0.0   \n",
       "...                                                   ...  ...   \n",
       "369265  brain meant processing million tweet post vide...  0.0   \n",
       "369266  blockchain enthusiast philanthropist slave jav...  0.0   \n",
       "369267  mathematician developer amazon previously geob...  0.0   \n",
       "369268    passionate nature software developer profession  0.0   \n",
       "369269  postdoc gipplab unigoettingen phd unikonstanz ...  0.0   \n",
       "\n",
       "                                                   tweets    label  \\\n",
       "0       happy share draftmateai support day free trial...  positiv   \n",
       "1       integrate chatgpt marketo smart campaign disco...  positiv   \n",
       "2       pleased announce new patentpending technology ...  positiv   \n",
       "3       starting tire scolded chatgpt slight perceived...  neutral   \n",
       "4       spartajustice it notable wikipedia entry john ...  positiv   \n",
       "...                                                   ...      ...   \n",
       "369265  chatgpt biggest smartest brain world right now...  negativ   \n",
       "369266  levelsso happy chatgpt team com revolutionary ...  positiv   \n",
       "369267  russel chatgpt it funny take long time answer ...  neutral   \n",
       "369268  wondering difference jasper chatgpt gpt chatgp...  positiv   \n",
       "369269  chatgpt similar llm pose challenge academic in...  positiv   \n",
       "\n",
       "                             date  \n",
       "0       2023-04-26 13:02:16+00:00  \n",
       "1       2023-04-26 13:02:06+00:00  \n",
       "2       2023-04-26 13:02:05+00:00  \n",
       "3       2023-04-26 13:02:00+00:00  \n",
       "4       2023-04-26 13:01:52+00:00  \n",
       "...                           ...  \n",
       "369265  2022-12-05 17:11:10+00:00  \n",
       "369266  2022-12-05 17:10:31+00:00  \n",
       "369267  2022-12-05 17:09:04+00:00  \n",
       "369268  2022-12-05 17:08:44+00:00  \n",
       "369269  2022-12-05 17:08:20+00:00  \n",
       "\n",
       "[369270 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1787f6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    362603\n",
       "1.0      6667\n",
       "Name: SC, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.SC.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5463aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('datasets/sentiment_chatgpt_sc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4dcb4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists = result[result.SC == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0065e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6667"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d865e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_description</th>\n",
       "      <th>SC</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sell rsi bybit recommendation short ticker ios...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:00:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sell rsi bybit recommendation short ticker ilv...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:59:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sell rsi bybit recommendation short ticker flm...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:53:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sell rsi bybit recommendation short ticker fil...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-04-26 12:53:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sell rsi bybit recommendation short ticker eth...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:52:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367973</th>\n",
       "      <td>attract complication easily distracted sing so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chatgpt thought dalle too favourite</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 21:32:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368229</th>\n",
       "      <td>hate speech outlet out moving arisinfosecexchange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chatgpt big brother share wisdom experience pr...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 20:47:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368478</th>\n",
       "      <td>ligthen it joke</td>\n",
       "      <td>1.0</td>\n",
       "      <td>shut down immediately thing advancement destro...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 20:02:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369022</th>\n",
       "      <td>hacker collective fighting techenabled abuse n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cool screenshots chatgpt racist writing vulner...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 18:12:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369044</th>\n",
       "      <td>greatest greater fool mattsbytesfosstodonorg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>milton friedman lot answer economics chatgpt o...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 18:06:32+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_description   SC  \\\n",
       "14      chatgpt powered free trading signal let grow m...  1.0   \n",
       "22      chatgpt powered free trading signal let grow m...  1.0   \n",
       "40      chatgpt powered free trading signal let grow m...  1.0   \n",
       "41      chatgpt powered free trading signal let grow m...  1.0   \n",
       "54      chatgpt powered free trading signal let grow m...  1.0   \n",
       "...                                                   ...  ...   \n",
       "367973  attract complication easily distracted sing so...  1.0   \n",
       "368229  hate speech outlet out moving arisinfosecexchange  1.0   \n",
       "368478                                    ligthen it joke  1.0   \n",
       "369022  hacker collective fighting techenabled abuse n...  1.0   \n",
       "369044       greatest greater fool mattsbytesfosstodonorg  1.0   \n",
       "\n",
       "                                                   tweets    label  \\\n",
       "14      sell rsi bybit recommendation short ticker ios...  positiv   \n",
       "22      sell rsi bybit recommendation short ticker ilv...  positiv   \n",
       "40      sell rsi bybit recommendation short ticker flm...  positiv   \n",
       "41      sell rsi bybit recommendation short ticker fil...  neutral   \n",
       "54      sell rsi bybit recommendation short ticker eth...  positiv   \n",
       "...                                                   ...      ...   \n",
       "367973                chatgpt thought dalle too favourite  negativ   \n",
       "368229  chatgpt big brother share wisdom experience pr...  positiv   \n",
       "368478  shut down immediately thing advancement destro...  positiv   \n",
       "369022  cool screenshots chatgpt racist writing vulner...  negativ   \n",
       "369044  milton friedman lot answer economics chatgpt o...  negativ   \n",
       "\n",
       "                             date  \n",
       "14      2023-04-26 13:00:16+00:00  \n",
       "22      2023-04-26 12:59:29+00:00  \n",
       "40      2023-04-26 12:53:58+00:00  \n",
       "41      2023-04-26 12:53:25+00:00  \n",
       "54      2023-04-26 12:52:37+00:00  \n",
       "...                           ...  \n",
       "367973  2022-12-05 21:32:20+00:00  \n",
       "368229  2022-12-05 20:47:28+00:00  \n",
       "368478  2022-12-05 20:02:15+00:00  \n",
       "369022  2022-12-05 18:12:28+00:00  \n",
       "369044  2022-12-05 18:06:32+00:00  \n",
       "\n",
       "[6667 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4fa77036",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists = scientists.drop('SC', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45107bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_description</th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>sell rsi bybit recommendation short ticker ios...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 13:00:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>sell rsi bybit recommendation short ticker ilv...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:59:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>sell rsi bybit recommendation short ticker flm...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:53:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>sell rsi bybit recommendation short ticker fil...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-04-26 12:53:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>chatgpt powered free trading signal let grow m...</td>\n",
       "      <td>sell rsi bybit recommendation short ticker eth...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2023-04-26 12:52:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367973</th>\n",
       "      <td>attract complication easily distracted sing so...</td>\n",
       "      <td>chatgpt thought dalle too favourite</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 21:32:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368229</th>\n",
       "      <td>hate speech outlet out moving arisinfosecexchange</td>\n",
       "      <td>chatgpt big brother share wisdom experience pr...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 20:47:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368478</th>\n",
       "      <td>ligthen it joke</td>\n",
       "      <td>shut down immediately thing advancement destro...</td>\n",
       "      <td>positiv</td>\n",
       "      <td>2022-12-05 20:02:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369022</th>\n",
       "      <td>hacker collective fighting techenabled abuse n...</td>\n",
       "      <td>cool screenshots chatgpt racist writing vulner...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 18:12:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369044</th>\n",
       "      <td>greatest greater fool mattsbytesfosstodonorg</td>\n",
       "      <td>milton friedman lot answer economics chatgpt o...</td>\n",
       "      <td>negativ</td>\n",
       "      <td>2022-12-05 18:06:32+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_description  \\\n",
       "14      chatgpt powered free trading signal let grow m...   \n",
       "22      chatgpt powered free trading signal let grow m...   \n",
       "40      chatgpt powered free trading signal let grow m...   \n",
       "41      chatgpt powered free trading signal let grow m...   \n",
       "54      chatgpt powered free trading signal let grow m...   \n",
       "...                                                   ...   \n",
       "367973  attract complication easily distracted sing so...   \n",
       "368229  hate speech outlet out moving arisinfosecexchange   \n",
       "368478                                    ligthen it joke   \n",
       "369022  hacker collective fighting techenabled abuse n...   \n",
       "369044       greatest greater fool mattsbytesfosstodonorg   \n",
       "\n",
       "                                                   tweets    label  \\\n",
       "14      sell rsi bybit recommendation short ticker ios...  positiv   \n",
       "22      sell rsi bybit recommendation short ticker ilv...  positiv   \n",
       "40      sell rsi bybit recommendation short ticker flm...  positiv   \n",
       "41      sell rsi bybit recommendation short ticker fil...  neutral   \n",
       "54      sell rsi bybit recommendation short ticker eth...  positiv   \n",
       "...                                                   ...      ...   \n",
       "367973                chatgpt thought dalle too favourite  negativ   \n",
       "368229  chatgpt big brother share wisdom experience pr...  positiv   \n",
       "368478  shut down immediately thing advancement destro...  positiv   \n",
       "369022  cool screenshots chatgpt racist writing vulner...  negativ   \n",
       "369044  milton friedman lot answer economics chatgpt o...  negativ   \n",
       "\n",
       "                             date  \n",
       "14      2023-04-26 13:00:16+00:00  \n",
       "22      2023-04-26 12:59:29+00:00  \n",
       "40      2023-04-26 12:53:58+00:00  \n",
       "41      2023-04-26 12:53:25+00:00  \n",
       "54      2023-04-26 12:52:37+00:00  \n",
       "...                           ...  \n",
       "367973  2022-12-05 21:32:20+00:00  \n",
       "368229  2022-12-05 20:47:28+00:00  \n",
       "368478  2022-12-05 20:02:15+00:00  \n",
       "369022  2022-12-05 18:12:28+00:00  \n",
       "369044  2022-12-05 18:06:32+00:00  \n",
       "\n",
       "[6667 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "568c35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientists.to_csv('datasets/sentiment_scientists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e75516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
