{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34062d6",
   "metadata": {},
   "source": [
    "# Analysis of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00473a",
   "metadata": {},
   "source": [
    "### Research question: What is the impact of the emerging of AI on the population based on tweets \n",
    "#### Analysis: Sentiment Analysis through NLP, focus on ChatGPT\n",
    "- Categorize tweets: positive, negative, neutral \n",
    "- Frequency of words used, what type of words\n",
    "- Evolution of the sentiment analysis: from the beginning of the release of ChatGPT until recently \n",
    "- Fequency of tweets made about AI (mean of tweets per person) \n",
    "- Try to work with threads (to be continued...)\n",
    "- Categorize tweets to workers, students, reasearchers (professors) and see if the sentiment analysis is different for these categories \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5f601",
   "metadata": {},
   "source": [
    "### Some references for the sentiment analysis\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/\n",
    "- https://huggingface.co/blog/sentiment-analysis-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdad096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65a82f",
   "metadata": {},
   "source": [
    "## Exploratory analysis with labeled dataset\n",
    "* dataset contains only english tweets\n",
    "* tweets about ChatGPT gathered for a month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32675764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9869d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162676</th>\n",
       "      <td>162676</td>\n",
       "      <td>What Yann LeCun thinks of ChatGPT? https://t.c...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133155</th>\n",
       "      <td>133155</td>\n",
       "      <td>What does the future of Cybersecurity look lik...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103244</th>\n",
       "      <td>103244</td>\n",
       "      <td>OpenAI releasing ChatGPT will probably go down...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>39072</td>\n",
       "      <td>it's over! you guys broke ChatGPT, and now I c...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159712</th>\n",
       "      <td>159712</td>\n",
       "      <td>Tryna get chatGPT to write my project for me ðŸ”¥ðŸ”¥ðŸ”¥</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                             tweets   labels\n",
       "162676      162676  What Yann LeCun thinks of ChatGPT? https://t.c...      bad\n",
       "133155      133155  What does the future of Cybersecurity look lik...  neutral\n",
       "103244      103244  OpenAI releasing ChatGPT will probably go down...  neutral\n",
       "39072        39072  it's over! you guys broke ChatGPT, and now I c...      bad\n",
       "159712      159712   Tryna get chatGPT to write my project for me ðŸ”¥ðŸ”¥ðŸ”¥      bad"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4dbef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweets', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "550eefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is 219294\n"
     ]
    }
   ],
   "source": [
    "print(\"length of data is\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8793169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219294, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c4114fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "tweets        object\n",
       "labels        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e56638",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d117217b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    other software projects are now trying to repl...\n",
       "219290    i asked #chatgpt to write a #nye joke for seos...\n",
       "219291    chatgpt is being disassembled until it can onl...\n",
       "219292    2023 predictions by #chatgpt. nothing really s...\n",
       "219293     from chatgpt, neat stuff https://t.co/qjjuf2z2m0\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].str.lower()\n",
    "df['tweets'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4800650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    chatgpt: optimizing language models dialogue h...\n",
       "1    try talking chatgpt, new ai system optimized d...\n",
       "2    chatgpt: optimizing language models dialogue h...\n",
       "3    thrilled share chatgpt, new model optimized di...\n",
       "4    2 minutes ago, @openai released new chatgpt. \\...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining set containing all stopwords in english\n",
    "\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# cleaning and removing the above stop words list from the tweet text\n",
    "STOPWORDS = set(stopwordlist)\n",
    "\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda text: cleaning_stopwords(text))\n",
    "df['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7179aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                chatgpt neat stuff httpstcoqjjuf2z2m0\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing punctuations \n",
    "\n",
    "import string\n",
    "\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweet']= df['tweet'].apply(lambda x: cleaning_punctuations(x))\n",
    "df['tweet'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4693fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                chatgpt neat stuff httpstcoqjjuf2z2m0\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing repeating characters\n",
    "\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning_repeating_char(x))\n",
    "df['tweet'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2025af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                chatgpt neat stuff httpstcoqjjuf2z2m0\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing URLs\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning_URLs(x))\n",
    "df['tweet'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ddc3c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    software projects trying replicate chatgpt htt...\n",
       "219290    asked chatgpt write nye joke seos delivered nn...\n",
       "219291                       chatgpt disassembled dissemble\n",
       "219292    2023 predictions chatgpt nothing really specif...\n",
       "219293                chatgpt neat stuff httpstcoqjjuf2z2m0\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and removing mentions \n",
    "\n",
    "def remove_mentions(word):\n",
    "    return re.sub(r\"@\\S+\", \"\", word)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: remove_mentions(x))\n",
    "df['tweet'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a0f285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ajkuna\n",
      "[nltk_data]     Seipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b59ba29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219289    [software, projects, trying, replicate, chatgp...\n",
       "219290    [asked, chatgpt, write, nye, joke, seos, deliv...\n",
       "219291                   [chatgpt, disassembled, dissemble]\n",
       "219292    [2023, predictions, chatgpt, nothing, really, ...\n",
       "219293           [chatgpt, neat, stuff, httpstcoqjjuf2z2m0]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization of tweet text : process of splitting text into \n",
    "# smaller chuncks, called tokens \n",
    "# each tokey is an input to the machine learning algorithm as a featue\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "test2 = df['tweet'].apply(word_tokenize)\n",
    "test2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37368b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73838c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying stemming\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
