{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5c7c30",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97d0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# remove english stopwords with the help of the gensim library \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3acab2",
   "metadata": {},
   "source": [
    "## All the methods that will be used to preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fd60152",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2413093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and removing URLs\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "def remove_hyperlink(word):\n",
    "    return re.sub(r\"http\\S+\", \"\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "277447e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and removing mentions \n",
    "\n",
    "def remove_mentions(word):\n",
    "    return re.sub(r\"@\\S+\", \"\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0d4cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing emojis \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686ec862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and removing repeating characters\n",
    "\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d402ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941dbf6",
   "metadata": {},
   "source": [
    "## Example of data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b4f9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "# english language dataset \n",
    "\n",
    "df = pd.read_csv('datasets/sentiment.csv', usecols=['tweets','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2398d7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174246</th>\n",
       "      <td>This is 5 Script Idea for webseries by #ChatGP...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>#ChatGPT describes the interior life of a corg...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197369</th>\n",
       "      <td>Why check #crypto prices on other websites whe...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>I asked  #ChatGPT this question: \\n\\n\"Will AI ...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53288</th>\n",
       "      <td>Ripple CTO shuts down ChatGPT's XRP conspiracy...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets labels\n",
       "174246  This is 5 Script Idea for webseries by #ChatGP...   good\n",
       "13084   #ChatGPT describes the interior life of a corg...    bad\n",
       "197369  Why check #crypto prices on other websites whe...    bad\n",
       "35632   I asked  #ChatGPT this question: \\n\\n\"Will AI ...    bad\n",
       "53288   Ripple CTO shuts down ChatGPT's XRP conspiracy...    bad"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce912bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        107796\n",
       "good        56011\n",
       "neutral     55487\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b3395a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the labeling: neutral = 0, positive = 1, negative = -1\n",
    "\n",
    "df.labels = df.labels.replace('bad', -1)\n",
    "df.labels = df.labels.replace('good', 1)\n",
    "df.labels = df.labels.replace('neutral', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a2a1ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90147</th>\n",
       "      <td>ChatGPT is out here serving up real human dram...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115503</th>\n",
       "      <td>Even a robot knows this one ðŸ¤– #chatGPT #person...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24658</th>\n",
       "      <td>OpenAI ChatGPT is anti national..\\nI asked it ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191774</th>\n",
       "      <td>Delighted to hear this news, but it is frustra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82536</th>\n",
       "      <td>I asked #chatGPT to automate editorial decisio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  labels\n",
       "90147   ChatGPT is out here serving up real human dram...      -1\n",
       "115503  Even a robot knows this one ðŸ¤– #chatGPT #person...      -1\n",
       "24658   OpenAI ChatGPT is anti national..\\nI asked it ...      -1\n",
       "191774  Delighted to hear this news, but it is frustra...       0\n",
       "82536   I asked #chatGPT to automate editorial decisio...       0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7d8c4c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    107796\n",
       " 1     56011\n",
       " 0     55487\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "daaabbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have too much negative tweets compared to the other classes\n",
    "# we divide the set of negative tweets by 2\n",
    "\n",
    "mask = (df.labels == -1)\n",
    "idx, = np.where(mask)\n",
    "df = df.drop(df.index[idx[:len(idx)//2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fdc38cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    56011\n",
       " 0    55487\n",
       "-1    53898\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a31cee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10956\\4127977162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# lower cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "# lower cases \n",
    "df.tweets = df.tweets.str.lower()\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda text: remove_stopwords(text))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc74e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda x: cleaning_punctuations(x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda x: cleaning_URLs(x))\n",
    "df.tweets = df.tweets.apply(lambda x: remove_hyperlink(x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda x: remove_mentions(x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda x: emoji_pattern.sub(r'', x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f4a5fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    chatgpt optimizing language models dialogue  o...\n",
       "1    try talking chatgpt new ai optimized dialogue ...\n",
       "2    chatgpt optimizing language models dialogue  a...\n",
       "3    thrilled share chatgpt new model optimized dia...\n",
       "5    launched chatgpt new ai optimized dialogue  here \n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove numbers \n",
    "df.tweets = df.tweets.apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aafe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweets = df.tweets.apply(lambda x: cleaning_repeating_char(x))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "21fe9141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    chatgpt optimizing language models dialogue op...\n",
       "1    try talking chatgpt new optimized dialogue fee...\n",
       "2    chatgpt optimizing language models dialogue ma...\n",
       "3    thrilled share chatgpt new model optimized dia...\n",
       "5         launched chatgpt new optimized dialogue here\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove short words that are of no use \n",
    "df.tweets = df.tweets.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "df.tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d9cd5aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [chatgpt, optimizing, language, models, dialog...\n",
       "1    [try, talking, chatgpt, new, optimized, dialog...\n",
       "2    [chatgpt, optimizing, language, models, dialog...\n",
       "3    [thrilled, share, chatgpt, new, model, optimiz...\n",
       "5    [launched, chatgpt, new, optimized, dialogue, ...\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text normalization : tokenize the tweets \n",
    "# split tweets of text into tokens (individual words of terms)\n",
    "tokenize_tweets = df.tweets.apply(lambda x: x.split())\n",
    "tokenize_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_tweets = tokenize_tweets.apply(lambda text: stem_words(text))\n",
    "tokenize_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fed87d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN values \n",
    "df.tweets = tokenize_tweets \n",
    "\n",
    "df.tweets.isnull().values.any()\n",
    "df.tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2f8855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new csv file containing the preprocessed dataset\n",
    "df.to_csv('datasets/preprocessed_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb33b9b",
   "metadata": {},
   "source": [
    "## Defining the function for preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f80d59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocessing(df, path):\n",
    "    # lower cases \n",
    "    df = df.str.lower()\n",
    "    print(\"Text of tweets transformed to lower cases.\")\n",
    "    \n",
    "    # remove english stopwords with the help of the gensim library \n",
    "    df = df.apply(lambda text: remove_stopwords(text))\n",
    "    print(\"Removed stopwords from the text of tweets.\")\n",
    "    \n",
    "    #cleaning and removing punctuation\n",
    "    df = df.apply(lambda x: cleaning_punctuations(x))\n",
    "    print(\"Cleaned and removed the punctuations.\")\n",
    "    \n",
    "    # cleaning and removing URLs\n",
    "    df = df.apply(lambda x: cleaning_URLs(x))\n",
    "    df = df.apply(lambda x: remove_hyperlink(x))\n",
    "    print(\"Cleaned and removed the URLs and hyperlinks.\")\n",
    "    \n",
    "    # cleaning and removing mentions \n",
    "    df = df.apply(lambda x: remove_mentions(x))\n",
    "    print(\"Cleaned and removed the mentions.\")\n",
    "    \n",
    "    # removing emojis \n",
    "    df = df.apply(lambda x: emoji_pattern.sub(r'', x))\n",
    "    print(\"Removed the emojis.\")\n",
    "    \n",
    "    # remove numbers \n",
    "    df = df.apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "    print(\"Removed the numbers.\")\n",
    "    \n",
    "    # cleaning and removing repeating characters\n",
    "    df = df.apply(lambda x: cleaning_repeating_char(x))\n",
    "    print(\"Cleaned and removed the repeating characters.\")\n",
    "    \n",
    "    # remove short words that are of no use \n",
    "    df = df.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "    print(\"Removed the short words (length less than 3).\")\n",
    "    \n",
    "    # Text normalization : tokenize the tweets \n",
    "    # split tweets of text into tokens (individual words of terms)\n",
    "    tokenize_tweets = df.apply(lambda x: x.split())\n",
    "    print(\"Tokenized the text.\")\n",
    "    \n",
    "    # Normalization: use of PorterStemmer()\n",
    "    tokenize_tweets = tokenize_tweets.apply(lambda text: stem_words(text))\n",
    "    print(\"Normalized the text.\")\n",
    "    \n",
    "    # write new csv file containing the preprocessed dataset\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a5886",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset of the first month of launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea271471",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/preprocessed_chatgptfirst.csv'\n",
    "\n",
    "df = pd.read_csv('datasets/chatgptfirst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c353cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>country</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1598014056790622225</td>\n",
       "      <td>2022-11-30 18:00:15+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598014522098208769</td>\n",
       "      <td>2022-11-30 18:02:06+00:00</td>\n",
       "      <td>12179</td>\n",
       "      <td>889</td>\n",
       "      <td>1130</td>\n",
       "      <td>3252</td>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1598014741527527435</td>\n",
       "      <td>2022-11-30 18:02:58+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1598015493666766849</td>\n",
       "      <td>2022-11-30 18:05:58+00:00</td>\n",
       "      <td>561</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1598015509420994561</td>\n",
       "      <td>2022-11-30 18:06:01+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                 created_at  like_count  quote_count  \\\n",
       "0  1598014056790622225  2022-11-30 18:00:15+00:00           2            0   \n",
       "1  1598014522098208769  2022-11-30 18:02:06+00:00       12179          889   \n",
       "2  1598014741527527435  2022-11-30 18:02:58+00:00           2            0   \n",
       "3  1598015493666766849  2022-11-30 18:05:58+00:00         561            8   \n",
       "4  1598015509420994561  2022-11-30 18:06:01+00:00           1            0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0            0              0   \n",
       "1         1130           3252   \n",
       "2            0              1   \n",
       "3           25             66   \n",
       "4            0              0   \n",
       "\n",
       "                                               tweet country  \\\n",
       "0  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "1  Try talking with ChatGPT, our new AI system wh...     NaN   \n",
       "2  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "3  THRILLED to share that ChatGPT, our new model ...     NaN   \n",
       "4  As of 2 minutes ago, @OpenAI released their ne...     NaN   \n",
       "\n",
       "                                         photo_url city country_code  \n",
       "0                                              NaN  NaN          NaN  \n",
       "1                                              NaN  NaN          NaN  \n",
       "2  https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg  NaN          NaN  \n",
       "3  https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg  NaN          NaN  \n",
       "4                                              NaN  NaN          NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55f92650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['tweet'] # we only retrieve the text of the tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e71d9d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any NaN value\n",
    "df.isnull().values.any()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "101b6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e982d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
