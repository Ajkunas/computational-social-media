{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff158974",
   "metadata": {},
   "source": [
    "## XML pre trained model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446396d2",
   "metadata": {},
   "source": [
    "See papers below for more informations: \n",
    "* https://arxiv.org/pdf/2302.13795.pdf\n",
    "* https://aclanthology.org/2022.lrec-1.27/\n",
    "* https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdbe62",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97fcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "device    = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d9e7",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69353d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/sentiment_chatgpt.csv', usecols=['user_name', 'user_description', 'clean_tweets','tweets','label', 'date'])\n",
    "\n",
    "df.isnull().values.any()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f82b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df[df.date.dt.month == 12] # first month\n",
    "last = df[(df.date.dt.month == 4) ] # last month (april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction of the first month: \n",
    "\n",
    "sentences = list(first[\"tweets\"])\n",
    "\n",
    "pred = []\n",
    "# Perform sentiment analysis for each sentence\n",
    "for i, text in enumerate(sentences):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input).to(device)\n",
    "    scores = output.logits.detach().cpu().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # Get label with highest score\n",
    "    highest_score_label = config.id2label[np.argmax(scores)]\n",
    "    pred.append(highest_score_label)\n",
    "\n",
    "first[\"label\"] = pred\n",
    "first.to_csv('datasets/sentiment_first.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b755f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction of the last month: \n",
    "\n",
    "sentences = list(last[\"tweets\"])\n",
    "\n",
    "pred = []\n",
    "# Perform sentiment analysis for each sentence\n",
    "for i, text in enumerate(sentences):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input).to(device)\n",
    "    scores = output.logits.detach().cpu().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # Get label with highest score\n",
    "    highest_score_label = config.id2label[np.argmax(scores)]\n",
    "    pred.append(highest_score_label)\n",
    "\n",
    "last[\"label\"] = pred\n",
    "last.to_csv('datasets/sentiment_last.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
